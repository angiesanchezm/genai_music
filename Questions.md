# ğŸ“‹ Respuestas a Preguntas Clave del Caso TÃ©cnico

## Sobre Arquitectura

### 1. Â¿QuÃ© stack tecnolÃ³gico propones y por quÃ©?

#### Stack Elegido

| Componente | TecnologÃ­a | JustificaciÃ³n |
|------------|------------|---------------|
| Backend | FastAPI | Alto rendimiento, async nativo |
| OrquestaciÃ³n | LangGraph | State management robusto para multi-agente |
| LLM | GPT-4o | Balance calidad/costo |
| Vector DB | Pinecone | Escalable, serverless |
| WhatsApp | Twilio | Setup rÃ¡pido, confiable |
| Base de datos | SQLite | Simple para MVP, fÃ¡cil migrar a PostgreSQL |
| ContainerizaciÃ³n | Docker | Consistencia entre ambientes |


---

### 2. Â¿CÃ³mo manejarÃ­as la memoria y el contexto?

#### Memoria en 3 Capas

El agente consultarÃ­a capas en este orden:
Capa 1 â†’ contexto inmediato (respuestas rÃ¡pidas)
Capa 2 â†’ contexto extendido de la conversaciÃ³n
Capa 3 â†’ informaciÃ³n estable del cliente

**Capa 1: SesiÃ³n Activa (Redis, TTL 24h)**
  - Ãšltimos 10 mensajes
  - Estado actual del agente
  - Metadata temporal (prioridad, sentimiento)
  - Acceso muy rÃ¡pido (<1 ms)

**Capa 2: Historial Conversacional (Redis, TTL 7 dÃ­as)**
  - Historial completo de mensajes
  - Handoffs entre agentes
  - Resoluciones previas
  - Acceso rÃ¡pido (<5 ms)

**Capa 3: Perfil de Cliente (PostgreSQL, persistente)**
  - Datos del cliente (nombre, plan)
  - Historial de releases
  - Tickets cerrados
  - Preferencias
  - Acceso ~10 ms


**. Contexto compartido entre agentes**

Estado completo compartido entre todos los agentes.
Ej:
â†’ Sales Agent procesa
â†’ Usuario pregunta algo tÃ©cnico â†’ Handoff
â†’ Support Agent ve TODO el state
Responde contextualmente: "Veo que te interesa Premium..."
Info compartida: Historial completo, plan de interÃ©s, problemas reportados, sentiment, tool calls.

**DÃ³nde se almacena**
| Dato | Storage | DuraciÃ³n | Velocidad |
|------|---------|----------|-----------|
| Mensajes actuales | LangGraph State (RAM) | SesiÃ³n | InstantÃ¡neo |
| Checkpoints | MemorySaver (RAM) | App running | <1ms |
| Historial | SQLite | Permanente | 5-10ms |
| Knowledge base | Pinecone | Permanente | 50-100ms |


### 3. Â¿CÃ³mo funciona el handoff entre agentes?

#### **Router de 2 etapas:**
**Etapa 1: ClasificaciÃ³n de IntenciÃ³n (GPT-4o)**
- **SALES**: precio, plan, contratar, cotizaciÃ³n, onboarding
- **SUPPORT**: error, problema, lanzamiento, regalÃ­as, metadata
**Etapa 2: Routing Condicional (LangGraph)**
    # Mantener agente si no hay cambio de contexto
    # Nuevo routing

#### **Â¿CuÃ¡ndo se transfiere?**
**Triggers de handoff:**
1. **ExplÃ­cito**: Agent llama `escalate_to_human()` tool
2. **ImplÃ­cito**: DetecciÃ³n de keywords tÃ©cnicos en respuesta
3. **Por prioridad**: `priority_score >= 9.0` â†’ escalar a humano

#### **Â¿CÃ³mo se transfiere el contexto?**
**State completo se pasa sin modificaciÃ³n:**
    Support recibe state IDÃ‰NTICO
    Puede ver: historial, plan de interÃ©s, sentiment, todo

**Ejemplo mensaje de transiciÃ³n**:
```
Sales: "Te transfiero con soporte especializado..."
Support: "Entiendo que tienes un problema. 
         Veo que estabas interesado en Premium. 
         DÃ©jame ayudarte..."
```

---

## Sobre Escalabilidad

### 4. Si maÃ±ana el cliente quiere agregar Instagram y Telegram, Â¿quÃ© cambia?

#### Cambios Necesarios: MÃNIMOS

**Arquitectura Actual (Preparada para Multicanal)**

```python
# El sistema es independienre al canal de origen
# Todos los canales convergen

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WhatsApp â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
              â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”œâ”€â”€conversation_id+messageâ”€â–ºâ”‚ Orchestrator â”‚
â”‚ Telegram â”‚â”€â”€â”¤                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                
              â”‚                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                                   â–¼
â”‚Instagram â”‚â”€â”€â”¤                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                           â”‚    Agents    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   API    â”‚â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


Solo cambia: 
   - Input adapter (webhook especÃ­fico)
   - Output adapter (API especÃ­fica)
   - Formato de conversation_id
```

**AbstracciÃ³n: Conversation ID**

- Cada canal tiene su formato de conversation_id
- Pero todos convergen al mismo sistema
- El orchestrator no sabe (ni le importa) de dÃ³nde viene

---

### 5. Si el volumen de mensajes se multiplica por 10, Â¿quÃ© se rompe primero?

#### Cuellos de Botella

**Estado Actual (Capacidad)**

```python
# Setup actual:
- 1 instancia de FastAPI
- OpenAI API (rate limit: 10k RPM)
- ChromaDB local

# Capacidad estimada:
- ~100 mensajes/minuto
- ~6,000 mensajes/hora
- ~144,000 mensajes/dÃ­a
```

**Cuellos de Botella Identificados (10x = 60k msg/hora)**

```
#1: OpenAI API Rate Limits
RevisiÃ³n:
- RateLimitError en logs
- Mensajes en cola creciendo
- Timeouts

SoluciÃ³n:
- Upgrade a tier superior en OpenAI
- Implementar cola de mensajes
```

```
#2: Single API Instance
- FastAPI se puede saturar con 10x requests
- CPU/Memory del container se satura

Revision:
- Latencia aumenta >2 segundos
- Event loop bloqueado

SoluciÃ³n:
- Horizontal scaling (3-5 instancias)
- Load balancer (nginx)
-Auto-scaling basado en mÃ©tricas
```

```
#3: SQLite Store
- LÃ­mite**: ~1000 writes/seg
- Rompe en**: 500 mensajes concurrentes

SÃ­ntomas:
- Aumento exponencial de latencia
- Database bloqueada

SoluciÃ³n:
- Cambiar a PostgreSQL
- Multiples lecturas simultaneas
```

---

### 6. Si el cliente quiere agregar un tercer agente (RegalÃ­as/Pagos), Â¿quÃ© tendrÃ­as que modificar?

La arquitectura con LangGraph estÃ¡ diseÃ±ada para ser **plug-and-play** con nuevos agentes.


**Paso 1: Definir el Agente**
**Paso 2: Crear Herramientas del Agente**
Ej:
- Balance de regalÃ­as
- Ganancia por stream
- Retirar fondos

**Paso 3: Actualizar Router**
Enrutar al agente apropiado en base a keywords

**Paso 4: Agregar Nodo al Grafo LangGraph**
Incorporar nodo de agente al grafo

#### Diagrama: Antes vs DespuÃ©s

```
ANTES (2 agentes):
                Router
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                 â”‚
      Sales            Support
         
DESPUÃ‰S (3 agentes):
                Router
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        â”‚        â”‚         â”‚
      Sales   Support  Royalties  Human
         â”‚        â”‚        â”‚         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              (Handoffs fluidos)
```

#### Lo que no cambia:

```
- Infraestructura (Docker, Redis)
- API endpoints
- Validacion de seguridad
- AnÃ¡lisis de sentimiento
-  Sistema RAG (solo agregar mÃ¡s docs)
- Webhooks de canales
-  Agentes existentes (Sales, Support)
```

---

## Sobre Robustez

### 7. Â¿QuÃ© pasa si el LLM falla en medio de una conversaciÃ³n?

#### Estrategia de manejo de fallos

**Nivel 1: Retry con Backoff Exponencial**
Llama al LLM con retry automÃ¡tico.
    Retry strategy:
        - Intento 1: Inmediato
        - Intento 2: DespuÃ©s de 2 segundos
        - Intento 3: DespuÃ©s de 4 segundos
        - Si falla: surge excepciÃ³n
        
**Nivel 2: Respuestas Pre-definidas (Fallback)**

```python
FALLBACK_RESPONSES = {
    "sales": {
        "greeting": "Hola, soy tu asistente de ventas. Â¿En quÃ© puedo ayudarte hoy?",
        "technical_issue": "Disculpa, estoy teniendo dificultades tÃ©cnicas. "
                          "Â¿PodrÃ­as intentar en unos momentos o prefieres hablar con un humano?",
        "pricing": "Tenemos tres planes: BÃ¡sico ($19.99), Pro ($49.99) y Label ($99.99). "
                  "Â¿Sobre cuÃ¡l te gustarÃ­a saber mÃ¡s?",
    },
    "support": {
        "greeting": "Hola, soy tu asistente de soporte. Â¿QuÃ© problema necesitas resolver?",
        "technical_issue": "Disculpa las molestias tÃ©cnicas. "
                          "Voy a conectarte con un agente humano que te ayudarÃ¡.",
        "status_check": "Para consultar el estado de tu lanzamiento necesito el tÃ­tulo. "
                       "Â¿Puedes compartirlo?",
    }
}
```

**Nivel 3: Escalamiento a humano**

Fallbacks EspecÃ­ficos por Tipo de Error

    # Rate Limit
    openai.RateLimitError: {
        "message": "Estamos experimentando alto volumen. Espera 30 segundos.",
        "action": "retry_delayed",
        "delay": 30
    },
    
    # Timeout
    openai.Timeout: {
        "message": "La solicitud estÃ¡ tomando mÃ¡s tiempo del esperado. "
                  "Â¿Quieres esperar o hablamos en un momento?",
        "action": "retry_once",
        "escalate_after": 1
    },
    
    # API Error
    openai.APIError: {
        "message": "Estoy teniendo un problema tÃ©cnico. "
                  "DÃ©jame conectarte con un humano.",
        "action": "escalate_immediate",
        "escalate_after": 0
    }


---

### 8. Â¿CÃ³mo sabrÃ­as si el agente estÃ¡ funcionando bien?


**1. MÃ©tricas de Sistema (Logs estructurados)**

- Latencia promedio: <2 seg (target)
- Error rate: <1% (alert si >5%)
- Throughput: mensajes/seg

**2. MÃ©tricas de Calidad del Agente**

QUALITY_TARGETS = {
    "resolution_rate": 0.70,               # 70% resuelto sin humano
    "first_contact_resolution": 0.40,      # 40% en primer contacto
    "avg_messages_to_resolve": 3.0,        # Promedio 3 mensajes
    "escalation_rate": 0.10,               # <10% escalado
    "avg_handoffs_per_conversation": 0.5   # <0.5 handoffs promedio
}


**3. MÃ©tricas de Negocio**

BUSINESS_TARGETS = {
    "cost_per_conversation": 0.10,         # <$0.10 por conversaciÃ³n
    "human_hours_saved_per_week": 100,     # >100 horas/semana
    "tickets_automated_percentage": 0.70,  # >70% tickets
    "lead_to_signup_rate": 0.15,           # >15% conversiÃ³n
    "issue_resolution_time_hours": 2.0     # <2 horas promedio
}
Sistema de Alertas AutomÃ¡ticas basado en metricas


#### DetecciÃ³n Proactiva de Problemas

**1. Health Checks**
**2. Monitoreo sintetico**
test_conversations = [
    "Â¿CuÃ¡nto cuesta?",
    "Tengo un problema"
]
**2. DetecciÃ³n de anomalÃ­as**
Traffic < Baseline
Error rate > Baseline

---

### 9. Roadmap Realista de ImplementaciÃ³n

#### Fase 1: MVP (2 meses)

**Semanas 1-2: Inicializar**
- Setup infraestructura (FastAPI + Docker)
- IntegraciÃ³n WhatsApp (Twilio)
- Base de datos (SQLite)
- Logging estructurado

**Semanas 3-4: Agentes Core**
- Sales Agent (3 tools)
- Support Agent (4 tools)
- ClasificaciÃ³n GPT

**Semanas 5-6: OrquestaciÃ³n**
- LangGraph workflow
- State management
- Handoff entre agentes

**Semanas 7-8: Inteligencia y testing**
- RAG con Pinecone
- Sentiment analysis
- Priority scoring
- Seguridad (validaciÃ³n)

**Entregable**: Sistema funcional, 2 agentes, WhatsApp, 100 conversaciones prueba.

ENTREGABLE MES 1:
Sistema funcional con Router + Sales Agent
WhatsApp funcionando
DocumentaciÃ³n bÃ¡sica
Tests unitarios



#### Fase 2: ProducciÃ³n (4 meses)

**Mes 3: Optmizacion Inicial**
- PostgreSQL migration
- Redis
- Automatic Monitoring
- CI/CD

**Mes 4: Features**
- 3er agente: RegalÃ­as
- IntegraciÃ³n Asana (tickets auto)
- A/B testing de prompts
- Multi-idioma (ES + EN)

**Mes 5: Escala**
- EjecuciÃ³n de computo distribuida 
- Auto-scaling
- Backup automÃ¡tico diario
- Disaster recovery plan

**Mes 6: ExpansiÃ³n**
- Instagram, telegramm
- Voice incorporation
- Fine-tuning modelo custom
- Analytics predictivo

ENTREGABLE MES 6:
Sistema optimizado con datos reales
Latencia <500ms promedio
Costo reducido 30%
Sistema en producciÃ³n en la nube

